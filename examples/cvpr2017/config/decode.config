### configuration for viterbi decoding on the test data ###

action                      = viterbi-decoding
log-file                    = log/decode.iter-2.log

[viterbi-decoding]
output                      = labels
pruning-threshold           = 1000.0

[scorer]
type                        = framewise-neural-network-scorer
batch-size                  = 512
prior-file                  = results/iter-2/prior.vector
prior-scale                 = 1.0
logarithmize-network-output = false

[grammar]
type                        = left-regular
file                        = results/grammar.gz

[hidden-markov-model]
type                        = standard-hmm
model-file                  = results/iter-2/hmm_definition.vector
transition-probability-file = results/iter-2/transition_probabilities.vector

[features.feature-reader]
feature-cache               = data/split1.test.bin
buffer-size                 = 1
preprocessors               = windowing

[windowing]
type                        = windowing
window-size                 = 21

[features.label-writer]
feature-cache               = results/iter-2/decoding.test.labels

include config/network.config

[neural-network]
load-model-from             = results/iter-2

[neural-network.output-layer]
type                        = identity          # omit softmax -> obtain logarithmized network output
